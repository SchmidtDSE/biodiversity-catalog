{
  "hash": "f5db81407a6415907742fb0602f663a3",
  "result": {
    "markdown": "---\ntitle: \"Biodiversity Dataset Catalog\"\nformat: html\n---\n\n\n# Overview\n\nOur [Biodiversity Dataset Catalog](https://radiantearth.github.io/stac-browser/#/external/raw.githubusercontent.com/schmidtDSE/biodiversity-catalog/main/stac/v1/catalog.json?.language=en) seeks to make a range of biodiversty data more readily findable, accessible and interoperable (see [FAIR principles](https://www.go-fair.org/fair-principles/)), while in a manner consistent with data sovereignty and ethics ([CARE principles](https://www.gida-global.org/care)).  Data products listed here support access with portable, cloud native, high-performance protocols that avoid the need to download entire data files. When existing data providers already meet these objectives, those sources are simply linked from the catalog. Other sources are mirrored on a local object store based on an open source software platform which supports the widely used S3 API for cloud-native operations  ([MINIO](https://min.io/)).  Access to mirrored content may require [access keys](access_keys.html) to meet licensing and re-distribution policies of certain data providers. The entire setup, including catalog and object store, can be easily replicated on commodity hardware using only open source tools. \n\n# Data Access\n\nLarge geospatial raster and vector data can best be accessed with 'cloud-native' protocols such as the [virtual filesystem in GDAL](https://gdal.org/user/virtual_file_systems.html), a popular C(++) library widely used to power various open source geospatial applications. This approach obviates the need to download and store very large data files. It works in anywhere an internet connection is available, though best performance can be achieved on a high-bandwidth or local area network.\n\n## Account keys and settings\n\nAccess keys are required for data that is mirrored on the DSE cloud object store and for which licensing requirements prohibit re-distribution. Enter your `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` in `~/.aws/credentials` file or as environmental variables.\n\nTo let the software know that data is not hosted on AWS but rather, at an independent object store, we must specify the domain of the new location as `AWS_S3_ENDPOINT` environmental variable, and indicate that our system does not use 'virtual hosting' style paths, `AWS_VIRTUAL_HOSTING=FALSE`. Environmental variables can be set in `~/.bashrc` (most platforms) or `.Renviron` file (for RStudio users)); though for clarity we will show how they can be set directly in python or R.  See [GDAL VFS documentation](https://gdal.org/user/virtual_file_systems.html#vsis3) for details.\n\nSome data linked in this catalog is already available from public cloud-based object stores such as Azure, Google Storage, or AWS.  Note that the former two require their own virtual filesystem prefixes, `/vsiaz/` and `/vsigs` respectively, as described in the [docs](https://gdal.org/user/virtual_file_systems.html).\n\n## Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport os\nos.environ[\"AWS_NO_SIGN_REQUEST\"]=\"TRUE\" # anonymous access for public buckets\nos.environ[\"AWS_S3_ENDPOINT\"]=\"minio.carlboettiger.info\"\nos.environ[\"AWS_VIRTUAL_HOSTING\"]=\"FALSE\"\n```\n:::\n\n\nWe can then read in raster or vector files using the GDAL virtual filesystem (VFS) URLs given in the catalog (click the button to copy the URL to your clipbard)\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport rioxarray\n\nvfs_url = \"/vsis3/public-biodiversity/carbon/Irrecoverable_Carbon_2018/Irrecoverable_C_Total_2018.tif\"\n\nr = rioxarray.open_rasterio(vfs_url)\n```\n:::\n\n\n\n## R \n\nThis process is nearly identical using any of the popular spatial frameworks in R, e.g. `terra`, `stars`, or `sf`.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nSys.setenv(\"AWS_NO_SIGN_REQUEST\"=\"TRUE\")\nSys.setenv(\"AWS_S3_ENDPOINT\"=\"minio.carlboettiger.info\")\nSys.setenv(\"AWS_VIRTUAL_HOSTING\"=\"FALSE\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(terra)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nterra 1.7.29\n```\n:::\n\n```{.r .cell-code}\nvfs_url = \"/vsis3/public-biodiversity/carbon/Irrecoverable_Carbon_2018/Irrecoverable_C_Total_2018.tif\"\nr = rast(vfs_url)\n```\n:::\n\n\n\n## GDAL and lazy evaluation\n\nIt is worth becoming familiar with support for GDAL's lazy evaluation mechanisms in your preferred client platform. These can allow you to subset, crop, re-sample, and transform your data over the remote network connection, which can improve computational speed and saves available disk and RAM space. Illustrative examples of this in R and python are provided in the example notebooks on this site. \n\n\n\n\n\n\n\n## Categories of Data Access\n\nDatasets included in this catalog fall into several different categories of access:\n\n1. Data that is publicly available from a high-bandwidth source in optimized format. \n\n2. Data that is freely available under permissive licenses, but only from low-bandwidth hosts or in non-optimized formats. Data shared on scientific data repositories such as Zenodo usually fall in this category.\n\n3. Data that is freely available but under restricted use, typically requiring a request (automated or manual).  Such distributors often also have low-bandwidth distribution and formats of category 2.\n\n4. Data that is shared only privately or under explicit non-disclosure contracts.\n\n5. Sensitive or [sovereign data](https://www.gida-global.org/care) which can only be stored in approved geographic regions or accessed only from secure systems.\n\n\nThis catalog seeks to help research teams bridge across these diverse types and needs in biodiversity data while respecting necessary restrictions of each category using distributed and open source tooling. \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}